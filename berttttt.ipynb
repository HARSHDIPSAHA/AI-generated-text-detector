{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-06T15:02:19.058005Z","iopub.status.busy":"2024-10-06T15:02:19.057529Z","iopub.status.idle":"2024-10-06T15:02:20.030267Z","shell.execute_reply":"2024-10-06T15:02:20.029150Z","shell.execute_reply.started":"2024-10-06T15:02:19.057969Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.12.0' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-06T15:12:01.900890Z","iopub.status.busy":"2024-10-06T15:12:01.900069Z","iopub.status.idle":"2024-10-06T15:12:01.907214Z","shell.execute_reply":"2024-10-06T15:12:01.906322Z","shell.execute_reply.started":"2024-10-06T15:12:01.900840Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["import torch\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-06T15:05:05.952162Z","iopub.status.busy":"2024-10-06T15:05:05.951445Z","iopub.status.idle":"2024-10-06T15:09:59.372078Z","shell.execute_reply":"2024-10-06T15:09:59.371085Z","shell.execute_reply.started":"2024-10-06T15:05:05.952126Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7cdf1c827994fa490a83a6f41cf4743","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e0f944612ff4967979b8464dcd10d1c","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18ba127941474e14b33be248ec9a5b12","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4cc0fee14fca4997833640f83dc9d3c1","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2f35bea6f3a4a20a4fdf7df986ac4b5","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/881 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"013c93e3a790419096ac36888bfbf8d8","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/221 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75ccf886203a483aa17047034cd02626","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7520a040c589440aa112a2d4f1afd2f6","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112557266665135, max=1.0â€¦"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241006_150536-wzakee7k</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/harshdipsaha-netaji-subhas-university-of-technology/huggingface/runs/wzakee7k' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/harshdipsaha-netaji-subhas-university-of-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/harshdipsaha-netaji-subhas-university-of-technology/huggingface' target=\"_blank\">https://wandb.ai/harshdipsaha-netaji-subhas-university-of-technology/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/harshdipsaha-netaji-subhas-university-of-technology/huggingface/runs/wzakee7k' target=\"_blank\">https://wandb.ai/harshdipsaha-netaji-subhas-university-of-technology/huggingface/runs/wzakee7k</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='555' max='555' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [555/555 04:16, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.001422</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.000486</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.000300</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.000234</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.017400</td>\n","      <td>0.000215</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Model and tokenizer saved.\n","The predicted label for the given text is: ai\n"]}],"source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset\n","import pandas as pd\n","\n","df = pd.read_csv('/kaggle/input/aiiscoming2/LLM.csv')\n","label_mapping = {'student': 0, 'ai': 1}\n","df = df.dropna(subset=['Label'])\n","df['Label'] = df['Label'].map(label_mapping).astype('int64')\n","df.rename(columns={'Text': 'content', 'Label': 'label'}, inplace=True)\n","train_df, eval_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n","train_dataset = Dataset.from_pandas(train_df)\n","eval_dataset = Dataset.from_pandas(eval_df)\n","model_name = \"bert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples['content'], padding=\"max_length\", truncation=True)\n","\n","train_dataset = train_dataset.map(tokenize_function, batched=True)\n","eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    fp16=torch.cuda.is_available(),\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n",")\n","trainer.train()\n","\n","def save_model_and_tokenizer(model, tokenizer, model_path, tokenizer_path):\n","    model.save_pretrained(model_path)\n","    tokenizer.save_pretrained(tokenizer_path)\n","    print(\"Model and tokenizer saved.\")\n","\n","model_path = './bert_finetuned_model'\n","tokenizer_path = './bert_tokenizer'\n","save_model_and_tokenizer(model, tokenizer, model_path, tokenizer_path)\n","\n","def load_model_and_tokenizer(model_path, tokenizer_path):\n","    model = BertForSequenceClassification.from_pretrained(model_path)\n","    tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n","    return model, tokenizer\n","\n","model, tokenizer = load_model_and_tokenizer(model_path, tokenizer_path)\n","labels = {0: \"student\", 1: \"ai\"}\n","\n","def predict_text_category(dialogue, model, tokenizer):\n","    inputs = tokenizer(dialogue, return_tensors='pt', truncation=True, padding=True, max_length=512)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    logits = outputs.logits\n","    predicted_class = torch.argmax(logits, dim=1).item()\n","    return labels[predicted_class]\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-06T15:13:43.256840Z","iopub.status.busy":"2024-10-06T15:13:43.256486Z","iopub.status.idle":"2024-10-06T15:13:43.317625Z","shell.execute_reply":"2024-10-06T15:13:43.316712Z","shell.execute_reply.started":"2024-10-06T15:13:43.256808Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The predicted label for the given text is: student\n"]}],"source":["text = \"hello beautiful wanna go on date\"\n","predicted_label = predict_text_category(text, model, tokenizer)\n","print(f\"The predicted label for the given text is: {predicted_label}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-06T15:13:19.480643Z","iopub.status.busy":"2024-10-06T15:13:19.480229Z","iopub.status.idle":"2024-10-06T15:13:19.554793Z","shell.execute_reply":"2024-10-06T15:13:19.553603Z","shell.execute_reply.started":"2024-10-06T15:13:19.480604Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The predicted label for the given text is: ai\n"]}],"source":["ai_generated_text = \"Blockchain is revolutionizing education, providing personalized learning experiences to students all over the world.\"\n","predicted_label = predict_text_category(ai_generated_text, model, tokenizer)\n","print(f\"The predicted label for the given text is: {predicted_label}\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-06T15:03:34.342611Z","iopub.status.busy":"2024-10-06T15:03:34.342130Z","iopub.status.idle":"2024-10-06T15:03:37.421631Z","shell.execute_reply":"2024-10-06T15:03:37.420659Z","shell.execute_reply.started":"2024-10-06T15:03:34.342574Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-06T14:40:59.817270Z","iopub.status.busy":"2024-10-06T14:40:59.816719Z","iopub.status.idle":"2024-10-06T14:40:59.826670Z","shell.execute_reply":"2024-10-06T14:40:59.825410Z","shell.execute_reply.started":"2024-10-06T14:40:59.817222Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(1102, 2)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-06T15:11:43.626905Z","iopub.status.busy":"2024-10-06T15:11:43.626553Z","iopub.status.idle":"2024-10-06T15:11:43.691085Z","shell.execute_reply":"2024-10-06T15:11:43.690031Z","shell.execute_reply.started":"2024-10-06T15:11:43.626860Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The predicted label for the given text is: student\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"myenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
